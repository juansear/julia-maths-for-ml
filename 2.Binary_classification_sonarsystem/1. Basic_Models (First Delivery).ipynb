{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f2270d9",
   "metadata": {},
   "source": [
    "# Sonar System Object Classification\n",
    "\n",
    "In this project we apply basic machine learning algorithms to a simple binary classification problem, considering data given by a Sonar System. The aim is to characterize rocks and mines throw the patterns captured by the sonar, each one consists of the measure of energy in a time lapse in different frequencies and varying the angle. We are working within the *MLJ framework* of Julia, which is a compendium of different packages and functions to apply machine learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c902deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manipulate data\n",
    "using CSV \n",
    "using DataFrames\n",
    "# Data exploration and visualization\n",
    "using PrettyPrinting\n",
    "import Statistics\n",
    "# Create pseudo-random numbers\n",
    "using StableRNGs\n",
    "\n",
    "### Machine Learning Framework ### \n",
    "using MLJ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3288c35",
   "metadata": {},
   "source": [
    "## 1. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd8d253c",
   "metadata": {},
   "source": [
    "### 1.1 Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d85e98df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 61 columns (omitted printing of 52 columns)</p><table class=\"data-frame\"><thead><tr><th></th><th>0.0200</th><th>0.0371</th><th>0.0428</th><th>0.0207</th><th>0.0954</th><th>0.0986</th><th>0.1539</th><th>0.1601</th><th>0.3109</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th></tr></thead><tbody><tr><th>1</th><td>0.0453</td><td>0.0523</td><td>0.0843</td><td>0.0689</td><td>0.1183</td><td>0.2583</td><td>0.2156</td><td>0.3481</td><td>0.3337</td></tr><tr><th>2</th><td>0.0262</td><td>0.0582</td><td>0.1099</td><td>0.1083</td><td>0.0974</td><td>0.228</td><td>0.2431</td><td>0.3771</td><td>0.5598</td></tr><tr><th>3</th><td>0.01</td><td>0.0171</td><td>0.0623</td><td>0.0205</td><td>0.0205</td><td>0.0368</td><td>0.1098</td><td>0.1276</td><td>0.0598</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccccc}\n",
       "\t& 0.0200 & 0.0371 & 0.0428 & 0.0207 & 0.0954 & 0.0986 & 0.1539 & 0.1601 & 0.3109 & \\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0453 & 0.0523 & 0.0843 & 0.0689 & 0.1183 & 0.2583 & 0.2156 & 0.3481 & 0.3337 & $\\dots$ \\\\\n",
       "\t2 & 0.0262 & 0.0582 & 0.1099 & 0.1083 & 0.0974 & 0.228 & 0.2431 & 0.3771 & 0.5598 & $\\dots$ \\\\\n",
       "\t3 & 0.01 & 0.0171 & 0.0623 & 0.0205 & 0.0205 & 0.0368 & 0.1098 & 0.1276 & 0.0598 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×61 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m 0.0200  \u001b[0m\u001b[1m 0.0371  \u001b[0m\u001b[1m 0.0428  \u001b[0m\u001b[1m 0.0207  \u001b[0m\u001b[1m 0.0954  \u001b[0m\u001b[1m 0.0986  \u001b[0m\u001b[1m 0.1539  \u001b[0m\u001b[1m 0.1601  \u001b[0m\u001b[1m\u001b[0m ⋯\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │  0.0453   0.0523   0.0843   0.0689   0.1183   0.2583   0.2156   0.3481  ⋯\n",
       "   2 │  0.0262   0.0582   0.1099   0.1083   0.0974   0.228    0.2431   0.3771\n",
       "   3 │  0.01     0.0171   0.0623   0.0205   0.0205   0.0368   0.1098   0.1276\n",
       "\u001b[36m                                                              53 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "df = CSV.read(\"sonar.csv\",DataFrame)\n",
    "first(df,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9dec8",
   "metadata": {},
   "source": [
    "Note that there are many columns hidden and As we can see, the dataframe does not have a header, so we must built it and load again the data. The first \n",
    "columns represent signals (amount of energy) captured by the Sonar, each one in a specific frequency, the last column apparently contains the category labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "493c6d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>3 rows × 8 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>Freq54</th><th>Freq55</th><th>Freq56</th><th>Freq57</th><th>Freq58</th><th>Freq59</th><th>Freq60</th><th>Label</th></tr><tr><th></th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"String1\">String1</th></tr></thead><tbody><tr><th>1</th><td>0.0159</td><td>0.0072</td><td>0.0167</td><td>0.018</td><td>0.0084</td><td>0.009</td><td>0.0032</td><td>R</td></tr><tr><th>2</th><td>0.0048</td><td>0.0094</td><td>0.0191</td><td>0.014</td><td>0.0049</td><td>0.0052</td><td>0.0044</td><td>R</td></tr><tr><th>3</th><td>0.0095</td><td>0.018</td><td>0.0244</td><td>0.0316</td><td>0.0164</td><td>0.0095</td><td>0.0078</td><td>R</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& Freq54 & Freq55 & Freq56 & Freq57 & Freq58 & Freq59 & Freq60 & Label\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & String1\\\\\n",
       "\t\\hline\n",
       "\t1 & 0.0159 & 0.0072 & 0.0167 & 0.018 & 0.0084 & 0.009 & 0.0032 & R \\\\\n",
       "\t2 & 0.0048 & 0.0094 & 0.0191 & 0.014 & 0.0049 & 0.0052 & 0.0044 & R \\\\\n",
       "\t3 & 0.0095 & 0.018 & 0.0244 & 0.0316 & 0.0164 & 0.0095 & 0.0078 & R \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m3×8 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m Freq54  \u001b[0m\u001b[1m Freq55  \u001b[0m\u001b[1m Freq56  \u001b[0m\u001b[1m Freq57  \u001b[0m\u001b[1m Freq58  \u001b[0m\u001b[1m Freq59  \u001b[0m\u001b[1m Freq60  \u001b[0m\u001b[1m Label   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m String1 \u001b[0m\n",
       "─────┼────────────────────────────────────────────────────────────────────────\n",
       "   1 │  0.0159   0.0072   0.0167   0.018    0.0084   0.009    0.0032  R\n",
       "   2 │  0.0048   0.0094   0.0191   0.014    0.0049   0.0052   0.0044  R\n",
       "   3 │  0.0095   0.018    0.0244   0.0316   0.0164   0.0095   0.0078  R"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the header with a list\n",
    "header = [\"Freq$i\" for i=1:size(df,2)-1 ]\n",
    "push!(header,\"Label\")\n",
    "# Re Load data and set header\n",
    "df = CSV.read(\"sonar.csv\",DataFrame,header=header)\n",
    "\n",
    "# Watch last 7 columns and first 3 rows\n",
    "first(select(df, 54:61 ),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4a2979c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of the DataFrame (cols,rows): \t (208, 61) \n",
      "    \n",
      "Data Type/Format of the first 60 columns: \t Float64 \n",
      "    \n",
      "Data Type/Format of the last column: \t \t String1"
     ]
    }
   ],
   "source": [
    "print(\"Dimension of the DataFrame (cols,rows): \\t $(size(df)) \n",
    "    \\nData Type/Format of the first $(size(df,2)-1) columns: \\t $(typeof(df[1,1])) \n",
    "    \\nData Type/Format of the last column: \\t \\t $(typeof(df[1,end]))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b040121",
   "metadata": {},
   "source": [
    "So we have $N=208$ samples, and the dimension of the feature vector is $D=60$. Next, we are obtaining the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c673172f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>11 rows × 7 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th title=\"Symbol\">Symbol</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Float64\">Float64</th><th title=\"Int64\">Int64</th><th title=\"DataType\">DataType</th></tr></thead><tbody><tr><th>1</th><td>Freq50</td><td>0.020424</td><td>0.0</td><td>0.0179</td><td>0.0825</td><td>0</td><td>Float64</td></tr><tr><th>2</th><td>Freq51</td><td>0.0160687</td><td>0.0</td><td>0.0139</td><td>0.1004</td><td>0</td><td>Float64</td></tr><tr><th>3</th><td>Freq52</td><td>0.0134202</td><td>0.0008</td><td>0.0114</td><td>0.0709</td><td>0</td><td>Float64</td></tr><tr><th>4</th><td>Freq53</td><td>0.0107091</td><td>0.0005</td><td>0.00955</td><td>0.039</td><td>0</td><td>Float64</td></tr><tr><th>5</th><td>Freq54</td><td>0.0109409</td><td>0.001</td><td>0.0093</td><td>0.0352</td><td>0</td><td>Float64</td></tr><tr><th>6</th><td>Freq55</td><td>0.00929038</td><td>0.0006</td><td>0.0075</td><td>0.0447</td><td>0</td><td>Float64</td></tr><tr><th>7</th><td>Freq56</td><td>0.00822163</td><td>0.0004</td><td>0.00685</td><td>0.0394</td><td>0</td><td>Float64</td></tr><tr><th>8</th><td>Freq57</td><td>0.00782019</td><td>0.0003</td><td>0.00595</td><td>0.0355</td><td>0</td><td>Float64</td></tr><tr><th>9</th><td>Freq58</td><td>0.00794904</td><td>0.0003</td><td>0.0058</td><td>0.044</td><td>0</td><td>Float64</td></tr><tr><th>10</th><td>Freq59</td><td>0.00794135</td><td>0.0001</td><td>0.0064</td><td>0.0364</td><td>0</td><td>Float64</td></tr><tr><th>11</th><td>Freq60</td><td>0.00650721</td><td>0.0006</td><td>0.0053</td><td>0.0439</td><td>0</td><td>Float64</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& variable & mean & min & median & max & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Float64 & Float64 & Float64 & Float64 & Int64 & DataType\\\\\n",
       "\t\\hline\n",
       "\t1 & Freq50 & 0.020424 & 0.0 & 0.0179 & 0.0825 & 0 & Float64 \\\\\n",
       "\t2 & Freq51 & 0.0160687 & 0.0 & 0.0139 & 0.1004 & 0 & Float64 \\\\\n",
       "\t3 & Freq52 & 0.0134202 & 0.0008 & 0.0114 & 0.0709 & 0 & Float64 \\\\\n",
       "\t4 & Freq53 & 0.0107091 & 0.0005 & 0.00955 & 0.039 & 0 & Float64 \\\\\n",
       "\t5 & Freq54 & 0.0109409 & 0.001 & 0.0093 & 0.0352 & 0 & Float64 \\\\\n",
       "\t6 & Freq55 & 0.00929038 & 0.0006 & 0.0075 & 0.0447 & 0 & Float64 \\\\\n",
       "\t7 & Freq56 & 0.00822163 & 0.0004 & 0.00685 & 0.0394 & 0 & Float64 \\\\\n",
       "\t8 & Freq57 & 0.00782019 & 0.0003 & 0.00595 & 0.0355 & 0 & Float64 \\\\\n",
       "\t9 & Freq58 & 0.00794904 & 0.0003 & 0.0058 & 0.044 & 0 & Float64 \\\\\n",
       "\t10 & Freq59 & 0.00794135 & 0.0001 & 0.0064 & 0.0364 & 0 & Float64 \\\\\n",
       "\t11 & Freq60 & 0.00650721 & 0.0006 & 0.0053 & 0.0439 & 0 & Float64 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m11×7 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean       \u001b[0m\u001b[1m min     \u001b[0m\u001b[1m median  \u001b[0m\u001b[1m max     \u001b[0m\u001b[1m nmissing \u001b[0m\u001b[1m eltype   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol   \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Float64 \u001b[0m\u001b[90m Int64    \u001b[0m\u001b[90m DataType \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────────────────────────\n",
       "   1 │ Freq50    0.020424     0.0     0.0179    0.0825         0  Float64\n",
       "   2 │ Freq51    0.0160687    0.0     0.0139    0.1004         0  Float64\n",
       "   3 │ Freq52    0.0134202    0.0008  0.0114    0.0709         0  Float64\n",
       "   4 │ Freq53    0.0107091    0.0005  0.00955   0.039          0  Float64\n",
       "   5 │ Freq54    0.0109409    0.001   0.0093    0.0352         0  Float64\n",
       "   6 │ Freq55    0.00929038   0.0006  0.0075    0.0447         0  Float64\n",
       "   7 │ Freq56    0.00822163   0.0004  0.00685   0.0394         0  Float64\n",
       "   8 │ Freq57    0.00782019   0.0003  0.00595   0.0355         0  Float64\n",
       "   9 │ Freq58    0.00794904   0.0003  0.0058    0.044          0  Float64\n",
       "  10 │ Freq59    0.00794135   0.0001  0.0064    0.0364         0  Float64\n",
       "  11 │ Freq60    0.00650721   0.0006  0.0053    0.0439         0  Float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(select(df, 50:60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91141e4b",
   "metadata": {},
   "source": [
    "Note that the labels are `M` for mines and `R` for rocks.\n",
    "\n",
    "To analyse range values in frequency columns in one shot we can: \n",
    "- make groups by  `eltype`, obtaining two groups (frequencies and target)\n",
    "- Describe the mean,min and max over mean, median, max and number of missing value in the first group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3957d299",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"data-frame\"><p>6 rows × 4 columns</p><table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>max</th></tr><tr><th></th><th title=\"Symbol\">Symbol</th><th title=\"Union{Nothing, Float64}\">Union…</th><th title=\"Any\">Any</th><th title=\"Any\">Any</th></tr></thead><tbody><tr><th>1</th><td>variable</td><td></td><td>Freq1</td><td>Freq9</td></tr><tr><th>2</th><td>mean</td><td>0.281321</td><td>0.00650721</td><td>0.702155</td></tr><tr><th>3</th><td>min</td><td>0.0189433</td><td>0.0</td><td>0.0921</td></tr><tr><th>4</th><td>max</td><td>0.655823</td><td>0.0352</td><td>1.0</td></tr><tr><th>5</th><td>nmissing</td><td>0.0</td><td>0</td><td>0</td></tr><tr><th>6</th><td>eltype</td><td></td><td></td><td></td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& variable & mean & min & max\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Any\\\\\n",
       "\t\\hline\n",
       "\t1 & variable &  & Freq1 & Freq9 \\\\\n",
       "\t2 & mean & 0.281321 & 0.00650721 & 0.702155 \\\\\n",
       "\t3 & min & 0.0189433 & 0.0 & 0.0921 \\\\\n",
       "\t4 & max & 0.655823 & 0.0352 & 1.0 \\\\\n",
       "\t5 & nmissing & 0.0 & 0 & 0 \\\\\n",
       "\t6 & eltype &  &  &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m6×4 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m variable \u001b[0m\u001b[1m mean      \u001b[0m\u001b[1m min        \u001b[0m\u001b[1m max      \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Symbol   \u001b[0m\u001b[90m Union…    \u001b[0m\u001b[90m Any        \u001b[0m\u001b[90m Any      \u001b[0m\n",
       "─────┼───────────────────────────────────────────\n",
       "   1 │ variable \u001b[90m           \u001b[0m Freq1       Freq9\n",
       "   2 │ mean      0.281321   0.00650721  0.702155\n",
       "   3 │ min       0.0189433  0.0         0.0921\n",
       "   4 │ max       0.655823   0.0352      1.0\n",
       "   5 │ nmissing  0.0        0           0\n",
       "   6 │ eltype   \u001b[90m           \u001b[0m\u001b[90m            \u001b[0m\u001b[90m          \u001b[0m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "describe(groupby(describe(df,:mean,:min,:max,:nmissing,:eltype),:eltype)[1], :mean,:min,:max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff8ba6",
   "metadata": {},
   "source": [
    "We can see that the values of the feature vector for each sample are small floating point numbers between 0 and 1, so it is convenient to store them as `Float64` to avoid roundoff error, also we can be sure that there aren't missing values in the whole dataset.  \n",
    "\n",
    "Lets take a look on the number of rocks and mines in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b58e783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Mines (M): 111 \n",
      "Number of Rocks (R):  97"
     ]
    }
   ],
   "source": [
    "num_R = count(i->(i==\"R\"),df[:,end])\n",
    "num_M = count(i->(i==\"M\"),df[:,end])\n",
    "print(\"Number of Mines (M): $num_M \\nNumber of Rocks (R):  $num_R\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eafd12",
   "metadata": {},
   "source": [
    "As we can see, the distrbution of mines and rocks is not discrete-uniform, this is an important fact we have to consider when spliting the data into train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ea343d",
   "metadata": {},
   "source": [
    "### 1.2 Scientific Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7079a31",
   "metadata": {},
   "source": [
    "Lets analyse how the data is interpreted, which means, the Scitype of the variables stored in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf01fc2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌────────┬────────────┬─────────┐\n",
       "│\u001b[22m names  \u001b[0m│\u001b[22m scitypes   \u001b[0m│\u001b[22m types   \u001b[0m│\n",
       "├────────┼────────────┼─────────┤\n",
       "│ Freq54 │ Continuous │ Float64 │\n",
       "│ Freq55 │ Continuous │ Float64 │\n",
       "│ Freq56 │ Continuous │ Float64 │\n",
       "│ Freq57 │ Continuous │ Float64 │\n",
       "│ Freq58 │ Continuous │ Float64 │\n",
       "│ Freq59 │ Continuous │ Float64 │\n",
       "│ Freq60 │ Continuous │ Float64 │\n",
       "│ Label  │ Textual    │ String1 │\n",
       "└────────┴────────────┴─────────┘\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema(select(df, 54:61))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8099b7",
   "metadata": {},
   "source": [
    "The value in each cell of a Frequency column represents an amount of energy, so it is reasonable to let them be continuous Scitypes, but the Label column should be a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b0f7e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "┌───────┬──────────────────┬───────────────────────────────────┐\n",
       "│\u001b[22m names \u001b[0m│\u001b[22m scitypes         \u001b[0m│\u001b[22m types                             \u001b[0m│\n",
       "├───────┼──────────────────┼───────────────────────────────────┤\n",
       "│ Label │ OrderedFactor{2} │ CategoricalValue{String1, UInt32} │\n",
       "└───────┴──────────────────┴───────────────────────────────────┘\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = coerce( df, :Label => OrderedFactor)\n",
    "schema(select(df,:Label))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de4699",
   "metadata": {},
   "source": [
    "Now, the categorical labels identified are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0856ee7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{String1}:\n",
       " \"M\"\n",
       " \"R\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels(df.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a265073b",
   "metadata": {},
   "source": [
    "In the model assesment it is appropiate to interpret a mine as \"positive\" and a rock as \"negative\", so we ought to define the order $R < M$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b097984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{String1}:\n",
       " \"R\"\n",
       " \"M\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels!(df.Label, [\"R\",\"M\"])\n",
    "levels(df.Label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e930d776",
   "metadata": {},
   "source": [
    "One can check the order relation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdc10b6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category of first sample: R \n",
      "Category of last sample: M"
     ]
    }
   ],
   "source": [
    "print(\"Category of first sample: $(df.Label[1]) \\nCategory of last sample: $(df.Label[end])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c27156d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Label[1]<df.Label[end]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935e885e",
   "metadata": {},
   "source": [
    "## 2. Data Set Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c2013a",
   "metadata": {},
   "source": [
    "### 2.1 Input-Output split\n",
    "To make the input-output split (X,y structure) is very easy using the `unpack` function in the MLJ framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c08fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y, X = unpack(df, ==(:Label));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79418cad",
   "metadata": {},
   "source": [
    "### 2.2 Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5444d8",
   "metadata": {},
   "source": [
    "We are taking 70% of the data for training and the rest for testing. Remember that the amount of rocks and mines is not the same, so we have to guarante that the proportion won't change after the set split. \n",
    "\n",
    "The split is done over the data set **indices**, this is the common way in the MLJ framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44227ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get rocks indices\n",
    "rocks_idx = findall(==(\"R\"),y)\n",
    "# Get mines indices\n",
    "mines_idx = findall(==(\"M\"),y)\n",
    "\n",
    "# Set a random seed\n",
    "rng = StableRNG(0)\n",
    "# Make a random partition over mines indices \n",
    "train_mines , test_mines = partition( mines_idx , 0.7, shuffle=true, rng=rng)\n",
    "# Make a random partition over rocks indices \n",
    "train_rocks , test_rocks = partition( rocks_idx , 0.7, shuffle=true, rng=rng)\n",
    "\n",
    "\n",
    "\n",
    "# join mines and rocks (indices) for each set\n",
    "train = [train_mines ; train_rocks]\n",
    "test = [test_mines ; test_rocks];\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b07b1c",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54947384",
   "metadata": {},
   "source": [
    "### 3.1 Available Models\n",
    "\n",
    "After preprocessing our data, especially setting the categorical variables and the other scitypes, it is possible to know which models in the MLJ framework are aproppiate for our data, considering the structure $X,y$. This can be done using the function `models` along with the function `matching`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5e03094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier            \t (ScikitLearn)\n",
      "AdaBoostStumpClassifier       \t (DecisionTree)\n",
      "BaggingClassifier             \t (ScikitLearn)\n",
      "BayesianLDA                   \t (MultivariateStats)\n",
      "BayesianLDA                   \t (ScikitLearn)\n",
      "BayesianQDA                   \t (ScikitLearn)\n",
      "BayesianSubspaceLDA           \t (MultivariateStats)\n",
      "ConstantClassifier            \t (MLJModels)\n",
      "DSADDetector                  \t (OutlierDetectionNetworks)\n",
      "DecisionTreeClassifier        \t (BetaML)\n",
      "DecisionTreeClassifier        \t (DecisionTree)\n",
      "DeterministicConstantClassifier\t (MLJModels)\n",
      "DummyClassifier               \t (ScikitLearn)\n",
      "ESADDetector                  \t (OutlierDetectionNetworks)\n",
      "EvoTreeClassifier             \t (EvoTrees)\n",
      "ExtraTreesClassifier          \t (ScikitLearn)\n",
      "GaussianNBClassifier          \t (NaiveBayes)\n",
      "GaussianNBClassifier          \t (ScikitLearn)\n",
      "GaussianProcessClassifier     \t (ScikitLearn)\n",
      "GradientBoostingClassifier    \t (ScikitLearn)\n",
      "KNNClassifier                 \t (NearestNeighborModels)\n",
      "KNeighborsClassifier          \t (ScikitLearn)\n",
      "KernelPerceptronClassifier    \t (BetaML)\n",
      "LDA                           \t (MultivariateStats)\n",
      "LGBMClassifier                \t (LightGBM)\n",
      "LinearBinaryClassifier        \t (GLM)\n",
      "LinearSVC                     \t (LIBSVM)\n",
      "LogisticCVClassifier          \t (ScikitLearn)\n",
      "LogisticClassifier            \t (MLJLinearModels)\n",
      "LogisticClassifier            \t (ScikitLearn)\n",
      "MultinomialClassifier         \t (MLJLinearModels)\n",
      "NeuralNetworkClassifier       \t (MLJFlux)\n",
      "NuSVC                         \t (LIBSVM)\n",
      "PassiveAggressiveClassifier   \t (ScikitLearn)\n",
      "PegasosClassifier             \t (BetaML)\n",
      "PerceptronClassifier          \t (BetaML)\n",
      "PerceptronClassifier          \t (ScikitLearn)\n",
      "ProbabilisticSGDClassifier    \t (ScikitLearn)\n",
      "RandomForestClassifier        \t (BetaML)\n",
      "RandomForestClassifier        \t (DecisionTree)\n",
      "RandomForestClassifier        \t (ScikitLearn)\n",
      "RidgeCVClassifier             \t (ScikitLearn)\n",
      "RidgeClassifier               \t (ScikitLearn)\n",
      "SGDClassifier                 \t (ScikitLearn)\n",
      "SVC                           \t (LIBSVM)\n",
      "SVMClassifier                 \t (ScikitLearn)\n",
      "SVMLinearClassifier           \t (ScikitLearn)\n",
      "SVMNuClassifier               \t (ScikitLearn)\n",
      "SubspaceLDA                   \t (MultivariateStats)\n",
      "XGBoostClassifier             \t (XGBoost)\n"
     ]
    }
   ],
   "source": [
    "for m in models(matching(X, y))\n",
    "    println(rpad(m.name, 30), \"\\t ($(m.package_name))\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15014fd",
   "metadata": {},
   "source": [
    "As we can see, most models are implemented outside of the MLJ ecosystem; we therefore have to load models using the `@load` command and specifying the package where it comes from. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52958ec5",
   "metadata": {},
   "source": [
    "According to the theory we have seen in the signature, the choosen models are: \n",
    "- LinearSVC (Support vector machine with linear Kernel)\n",
    "- SVC (Support vector machine with RBF kernel)\n",
    "- LogisticClassifier (Logistic regression)\n",
    "- DecisionTreeClassifier (Ordinary Desicion Tree) \n",
    "- KNeighborsClassifier (K-Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d743ceb4",
   "metadata": {},
   "source": [
    "### 3.2 Single model Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb254a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import MLJScikitLearnInterface ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: For silent loading, specify `verbosity=0`. \n",
      "└ @ Main C:\\Users\\JSeba\\.julia\\packages\\MLJModels\\QEeNR\\src\\loading.jl:168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticClassifier(\n",
       "    penalty = \"l2\",\n",
       "    dual = false,\n",
       "    tol = 0.0001,\n",
       "    C = 1.0,\n",
       "    fit_intercept = true,\n",
       "    intercept_scaling = 1.0,\n",
       "    class_weight = nothing,\n",
       "    random_state = nothing,\n",
       "    solver = \"lbfgs\",\n",
       "    max_iter = 100,\n",
       "    multi_class = \"auto\",\n",
       "    verbose = 0,\n",
       "    warm_start = false,\n",
       "    n_jobs = nothing,\n",
       "    l1_ratio = nothing)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from the ScikitLearn ecosystem\n",
    "LogisticClassifier  = @load LogisticClassifier  pkg=ScikitLearn\n",
    "# Create a model instance with the default hyperparameters\n",
    "logistic_model = LogisticClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacea289",
   "metadata": {},
   "source": [
    "In MLJ, a **model** is an object that only serves as a container for the hyperparameters of the model. A **machine** is an object wrapping both a model and data and can contain information on the trained model; it does not fit the model by itself. However, it does check that the model is compatible with the scientific type of the data and will warn you otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8195f7f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Training Machine{LogisticClassifier,…}.\n",
      "└ @ MLJBase C:\\Users\\JSeba\\.julia\\packages\\MLJBase\\CMT6L\\src\\machines.jl:464\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Machine{LogisticClassifier,…} trained 1 time; caches data\n",
       "  model: MLJScikitLearnInterface.LogisticClassifier\n",
       "  args: \n",
       "    1:\tSource @548 ⏎ `Table{AbstractVector{Continuous}}`\n",
       "    2:\tSource @966 ⏎ `AbstractVector{OrderedFactor{2}}`\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build a machine\n",
    "logistic = machine(logistic_model, X, y)\n",
    "# Train the machine\n",
    "fit!(logistic, rows=train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b957114",
   "metadata": {},
   "source": [
    "Some Classifiers, as the logistic regression work, with *Probabilistic* predictions, the output value represents the probability of $y^{i}$ being positive (1 or `M`) given $X^{(i)}$. We can get this probabilistic values with the function `prediction`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d48384f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilistic prediction given test input\n",
    "ŷ_prob = predict(logistic, rows=test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72f3226",
   "metadata": {},
   "source": [
    "Also MLJ allows to show this information for one sample in a fancy way by using the  `@show` decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6043929c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ŷ_prob[1] = UnivariateFinite{OrderedFactor{2}}(R=>0.305, M=>0.695)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "         \u001b[97;1mUnivariateFinite{OrderedFactor{2}}\u001b[0m     \n",
       "     \u001b[38;5;8m┌                                        ┐\u001b[0m \n",
       "   R \u001b[38;5;8m┤\u001b[0m\u001b[38;5;2m■■■■■■■■■\u001b[0m 0.3045705477167904            \u001b[38;5;8m \u001b[0m \u001b[38;5;8m\u001b[0m\n",
       "   M \u001b[38;5;8m┤\u001b[0m\u001b[38;5;2m■■■■■■■■■■■■■■■■■■■■\u001b[0m 0.6954294522832096 \u001b[38;5;8m \u001b[0m \u001b[38;5;8m\u001b[0m\n",
       "     \u001b[38;5;8m└                                        ┘\u001b[0m "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@show ŷ_prob[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e28646",
   "metadata": {},
   "source": [
    "To get the prediction according to the decision boundary (typically 0.5) one might use `predict_mode` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8e68979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element CategoricalArrays.CategoricalArray{String1,1,UInt32}:\n",
       " \"M\"\n",
       " \"M\"\n",
       " \"M\"\n",
       " \"M\"\n",
       " \"R\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definite prediction over the test input\n",
    "ŷ = predict_mode(logistic, rows=test)\n",
    "ŷ[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333702a8",
   "metadata": {},
   "source": [
    "### 3.3 Model Assesment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a10426",
   "metadata": {},
   "source": [
    "In classification problems is it always useful to compute the confussion matrix to identify paterns and understand proportions of correct classification and deviations in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78202ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      R      │      M      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      R      │     24      │      7      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      M      │      5      │     26      │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat(ŷ,y[test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6d5632",
   "metadata": {},
   "source": [
    "In our case, using the Sonar System we rather to detect all the mines possible and tolerate some falsepositive rocks. So, the most suitable measure is the recall which is computed by \n",
    "$$ \\text{recall} = \\frac{TP}{TP+FN}$$\n",
    "the recall is also calle as True Positive rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb42b1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall in logistic regression: 0.7878787878787878"
     ]
    }
   ],
   "source": [
    "logistic_recall = recall(ŷ,y[test]);\n",
    "print(\"Recall in logistic regression: $logistic_recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e31a7da",
   "metadata": {},
   "source": [
    "### 3.4 Model Comparison\n",
    "Now we will train all the models selected in section 3.1, then evaluate and compare them by the recall metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "87fa1172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models \n",
    "Linear_SVC = @load LinearSVC verbosity=0\n",
    "SVC = @load SVC verbosity=0\n",
    "LogisticClassifier = @load LogisticClassifier pkg=ScikitLearn verbosity=0\n",
    "DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree  verbosity=0\n",
    "KNeighborsClassifier = @load KNeighborsClassifier  verbosity=0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "35cda1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all models in a list, so we can easily apply a cycle itering over them.\n",
    "Models = [ Linear_SVC, SVC, LogisticClassifier, DecisionTreeClassifier, KNeighborsClassifier];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "333b4e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Score: 0.8181818181818182 \t \t  ----->  LinearSVC\n",
      "\t Score: 0.8787878787878788 \t \t  ----->  SVC\n",
      "\t Score: 0.7878787878787878 \t \t  ----->  LogisticClassifier\n",
      "\t Score: 0.7272727272727273 \t \t  ----->  DecisionTreeClassifier\n",
      "\t Score: 0.7272727272727273 \t \t  ----->  KNeighborsClassifier\n"
     ]
    }
   ],
   "source": [
    "# Create an array to save the scores\n",
    "scores = []\n",
    "# Main cycle to train, predict and evaluate every model.\n",
    "for model in Models\n",
    "    instance = model()\n",
    "    mach = machine(instance, X , y)\n",
    "    fit!(mach, rows=train, verbosity=0)\n",
    "    \n",
    "    # Consider If the model has a probabilistic output or not\n",
    "    try\n",
    "        ŷ = predict_mode(mach, rows=test)\n",
    "    catch\n",
    "        ŷ = predict(mach, rows=test)\n",
    "    end\n",
    "    # Evaluating the model perfomance by recall metric\n",
    "    recall_score = recall(ŷ, y[test])\n",
    "    println(\"\\t Score: $recall_score \\t \\t  ----->  $(instance)\")\n",
    "    push!(scores,recall_score)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd76425",
   "metadata": {},
   "source": [
    "### 3.5 Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2b7bd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is SVC from the MLJLIBSVMInterface package"
     ]
    }
   ],
   "source": [
    "best_model = Models[findmax(scores)[2]]\n",
    "pkg, model_name  = split(string(best_model), \".\")\n",
    "print(\"The best model is $model_name from the $pkg package\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65553a29",
   "metadata": {},
   "source": [
    "The default hyperparameters are "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d60fb58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(\n",
       "    kernel = LIBSVM.Kernel.RadialBasis,\n",
       "    gamma = 0.0,\n",
       "    cost = 1.0,\n",
       "    cachesize = 200.0,\n",
       "    degree = 3,\n",
       "    coef0 = 0.0,\n",
       "    tolerance = 0.001,\n",
       "    shrinking = true,\n",
       "    probability = false)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = best_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae407ae",
   "metadata": {},
   "source": [
    "### Fitting analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "de387510",
   "metadata": {},
   "outputs": [],
   "source": [
    "mach = machine(instance, X , y)\n",
    "fit!(mach, rows=train, verbosity=0)\n",
    "ŷtrain = predict(mach, rows=train);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3e4b74",
   "metadata": {},
   "source": [
    "The confussion matrix for the trainning set is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "99cc4a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      R      │      M      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      R      │     55      │      3      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      M      │     13      │     75      │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(confmat(ŷtrain,y[train]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eba89283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Accuracy: \t 0.8904109589041096 \n",
      "Fitting Recall: \t 0.9615384615384616"
     ]
    }
   ],
   "source": [
    "accuracy_train = accuracy(ŷtrain,y[train])\n",
    "recall_train = recall(ŷtrain, y[train])\n",
    "print(\"Fitting Accuracy: \\t $accuracy_train \\nFitting Recall: \\t $recall_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0975d4",
   "metadata": {},
   "source": [
    "We can see that the fitting accuracy is almost 90%, which means that the fitting is not perfect, there are 3 false negatives and 13 false positives, but this is not a big issue. However, it reachs 96% in fitting recall, which is the choosen metric, this might be an explanation of model's succes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3452650d",
   "metadata": {},
   "source": [
    "### Performance on the test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30db97c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ŷtest = predict(mach, rows=test);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a532b28",
   "metadata": {},
   "source": [
    "Confussion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a6b248e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "              ┌───────────────────────────┐\n",
       "              │       Ground Truth        │\n",
       "┌─────────────┼─────────────┬─────────────┤\n",
       "│  Predicted  │      R      │      M      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      R      │     24      │      4      │\n",
       "├─────────────┼─────────────┼─────────────┤\n",
       "│      M      │      5      │     29      │\n",
       "└─────────────┴─────────────┴─────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(confmat(ŷtest,y[test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cbf668e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: \t 0.8548387096774194 \n",
      "Model Recall: \t \t 0.8787878787878788 \n",
      "Model Precision: \t 0.8529411764705882"
     ]
    }
   ],
   "source": [
    "# Compute usefull metrics between predictions and actual categories.\n",
    "accuracy_test = accuracy(ŷtest,y[test])\n",
    "recall_test = recall(ŷtest,y[test])\n",
    "precision_test = precision(ŷtest,y[test])\n",
    "print(\"Model Accuracy: \\t $accuracy_test \\nModel Recall: \\t \\t $recall_test \\nModel Precision: \\t $precision_test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855fef3e",
   "metadata": {},
   "source": [
    "With this train-test fixed split, the SVC reachs an accuracy of 85%, an extraordinary perfomance considering there where not hyperparameter tunning. The default kernel, Radial Basis, seems to be very apprropiate to the data. In conclussion, we avoid overfitting and obtain good generalization."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
